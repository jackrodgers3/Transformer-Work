{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-22T17:07:57.943578100Z",
     "start_time": "2023-06-22T17:07:57.838633300Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('Data/input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset in characters:  1115394\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of dataset in characters: \", len(text))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T17:07:57.943578100Z",
     "start_time": "2023-06-22T17:07:57.852016600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 100 characters:  First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "print(\"First 100 characters: \", text[:100])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T17:07:57.943578100Z",
     "start_time": "2023-06-22T17:07:57.869036700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "#making vocabulary\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T17:07:57.948591500Z",
     "start_time": "2023-06-22T17:07:57.890600800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 43, 50, 50, 53, 1, 58, 46, 43, 56, 43, 8]\n",
      "Hello there\n"
     ]
    }
   ],
   "source": [
    "#making encoder (string -> #) and decoder (# -> string)\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "print(encode(\"Hello there.\"))\n",
    "print(decode(encode(\"Hello there\")))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T17:07:57.994805800Z",
     "start_time": "2023-06-22T17:07:57.943578100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
     ]
    }
   ],
   "source": [
    "#encoding entire text dataset\n",
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T17:09:06.353134600Z",
     "start_time": "2023-06-22T17:08:51.633898Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "#splitting into train and validation data sets\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "valid_data = data[n:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T17:10:22.038644600Z",
     "start_time": "2023-06-22T17:10:22.011315900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T17:11:45.736545400Z",
     "start_time": "2023-06-22T17:11:45.674997600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the target: 47\n",
      "when input is tensor([18, 47]) the target: 56\n",
      "when input is tensor([18, 47, 56]) the target: 57\n",
      "when input is tensor([18, 47, 56, 57]) the target: 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T17:17:24.157485300Z",
     "start_time": "2023-06-22T17:17:24.137038200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[41, 47, 56, 41, 59, 51, 57, 54],\n",
      "        [51, 43,  6,  1, 42, 53,  1, 63],\n",
      "        [32, 59, 58, 53, 56, 10,  0, 13],\n",
      "        [ 1, 57, 46, 43,  1, 57, 54, 43]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[47, 56, 41, 59, 51, 57, 54, 43],\n",
      "        [43,  6,  1, 42, 53,  1, 63, 53],\n",
      "        [59, 58, 53, 56, 10,  0, 13, 46],\n",
      "        [57, 46, 43,  1, 57, 54, 43, 39]])\n",
      "------\n",
      "when input is [41] the target: 47\n",
      "when input is [41, 47] the target: 56\n",
      "when input is [41, 47, 56] the target: 41\n",
      "when input is [41, 47, 56, 41] the target: 59\n",
      "when input is [41, 47, 56, 41, 59] the target: 51\n",
      "when input is [41, 47, 56, 41, 59, 51] the target: 57\n",
      "when input is [41, 47, 56, 41, 59, 51, 57] the target: 54\n",
      "when input is [41, 47, 56, 41, 59, 51, 57, 54] the target: 43\n",
      "when input is [51] the target: 43\n",
      "when input is [51, 43] the target: 6\n",
      "when input is [51, 43, 6] the target: 1\n",
      "when input is [51, 43, 6, 1] the target: 42\n",
      "when input is [51, 43, 6, 1, 42] the target: 53\n",
      "when input is [51, 43, 6, 1, 42, 53] the target: 1\n",
      "when input is [51, 43, 6, 1, 42, 53, 1] the target: 63\n",
      "when input is [51, 43, 6, 1, 42, 53, 1, 63] the target: 53\n",
      "when input is [32] the target: 59\n",
      "when input is [32, 59] the target: 58\n",
      "when input is [32, 59, 58] the target: 53\n",
      "when input is [32, 59, 58, 53] the target: 56\n",
      "when input is [32, 59, 58, 53, 56] the target: 10\n",
      "when input is [32, 59, 58, 53, 56, 10] the target: 0\n",
      "when input is [32, 59, 58, 53, 56, 10, 0] the target: 13\n",
      "when input is [32, 59, 58, 53, 56, 10, 0, 13] the target: 46\n",
      "when input is [1] the target: 57\n",
      "when input is [1, 57] the target: 46\n",
      "when input is [1, 57, 46] the target: 43\n",
      "when input is [1, 57, 46, 43] the target: 1\n",
      "when input is [1, 57, 46, 43, 1] the target: 57\n",
      "when input is [1, 57, 46, 43, 1, 57] the target: 54\n",
      "when input is [1, 57, 46, 43, 1, 57, 54] the target: 43\n",
      "when input is [1, 57, 46, 43, 1, 57, 54, 43] the target: 39\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(23)\n",
    "batch_size = 4 #number of sequences we process in parallel\n",
    "block_size = 8 #maximum context length for predictions\n",
    "\n",
    "def get_batch(split):\n",
    "    #generate small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else valid_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "print('------')\n",
    "\n",
    "for b in range(batch_size): #batch dimension\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T17:25:01.077365Z",
     "start_time": "2023-06-22T17:25:01.052855900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        #each token directly leads off logits for the next token\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) #(B,T,C)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        #idx is (B,T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            #get predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] #becomes (B, C)\n",
    "            #apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=1) #(B, C)\n",
    "            #sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) #(B, 1)\n",
    "            #append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) #(B, T+1)\n",
    "        return idx"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T17:53:59.811977400Z",
     "start_time": "2023-06-22T17:53:59.779152400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "torch.Size([65])\n",
      "c\n",
      "tensor([-1.2679, -0.3498, -0.2310,  1.7544, -1.8384, -2.0511,  3.1869, -1.2115,\n",
      "         0.3610, -0.3943, -0.2203, -1.2162,  0.5036,  0.2842,  0.0109, -2.4267,\n",
      "         0.6823,  1.0333, -1.5323, -0.2298, -0.7750,  0.5155,  1.0962,  0.3386,\n",
      "        -0.1593, -0.1236, -0.1805,  0.3471,  0.2264, -1.9593,  0.1529, -1.7791,\n",
      "         0.2220,  0.6876, -1.4499, -0.3027,  0.4494, -0.9640, -0.4338, -0.8066,\n",
      "        -0.8323, -1.5387,  1.0941, -0.0093, -2.2536, -0.0849, -0.1019,  1.0514,\n",
      "        -0.6846,  0.4518, -1.1508,  1.7803,  0.7213,  0.1564,  1.0953,  1.5976,\n",
      "         0.0942, -0.6389,  1.6595, -0.3800, -0.7967, -0.1021,  1.1271,  3.1114,\n",
      "        -2.3754], grad_fn=<SliceBackward0>)\n",
      "tensor(4.4945, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model1 = BigramLanguageModel(vocab_size)\n",
    "logits, loss = model1(xb, yb)\n",
    "print(logits.shape)\n",
    "sing_channel = logits[0, :]\n",
    "print(sing_channel.shape)\n",
    "print(chars[41])\n",
    "print(sing_channel)\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T17:54:20.256789500Z",
     "start_time": "2023-06-22T17:54:20.209895800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fu-b;Wzc$fHV 'c, Wd;eI..VArT $L\n",
      "lAaH!hoqcy?VZV Rib;fNdGYHinytJJ'Vrl;UcUuZnGdzvom.woQio:Y,nxNVrwgHbZo\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(model1.generate(idx, max_new_tokens=100)[0].tolist()))\n",
    "#obviously the model is horrible because we haven't even trained it yet."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T17:56:43.390435800Z",
     "start_time": "2023-06-22T17:56:43.330406400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "#create optimizer\n",
    "optimizer = torch.optim.AdamW(model1.parameters(), lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T17:58:23.023127300Z",
     "start_time": "2023-06-22T17:58:22.975266800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.503936290740967\n"
     ]
    }
   ],
   "source": [
    "#get bigger batch size and train\n",
    "batch_size = 32\n",
    "for steps in range(1000):\n",
    "    #sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    #evaluate loss\n",
    "    logits, loss = model1(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T18:06:19.164202100Z",
     "start_time": "2023-06-22T18:06:15.495040500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UROf Hed stenofo the f haland sing ESTothery dy.\n",
      "\n",
      "Kat--be utely, y tcod t, t ndildit Exf bons\n",
      "\n",
      "wanimy h awith lit--il an sere d wise usifr norug, buefe okissu, 't d INGertou wh nomalenoupo hordor, l r hare thierye thel eld?ontineneis,\n",
      "Anthome\n",
      "\n",
      "LO:\n",
      "HERENG iea thishake the vend t nd wasporo.\n",
      "TUnd? n brd thest-gr w, the IUSSI d swncase m plind, taret\n",
      "A: thewoun thisestht:\n",
      "An?\n",
      "S he men VO:\n",
      "\n",
      "SADYejuraulllivinortey l; y lpe we, aru wicor ar: hio th,\n",
      "Mal r?\n",
      "I not ngs se YTh seiay bllayok 'sir, tOHedith\n"
     ]
    }
   ],
   "source": [
    "print(decode(model1.generate(idx = torch.zeros((1,1), dtype=torch.long), max_new_tokens=500)[0].tolist()))\n",
    "#as we can see, a little better"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T18:06:48.861146100Z",
     "start_time": "2023-06-22T18:06:48.703053300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 8, 32])"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#consider following example\n",
    "\n",
    "torch.manual_seed(23)\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T22:53:17.972708500Z",
     "start_time": "2023-06-22T22:53:17.894002700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1] #(t, C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)\n",
    "#we want the current token to be influenced by information from the previous tokens, so we take an average of the previous tokens and make that the current token.  This approach is a little sloppy though since a lot of information is lost"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T22:53:18.535292800Z",
     "start_time": "2023-06-22T22:53:18.487801600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.9012,  0.5656, -0.4882,  0.7507,  0.5893, -0.4552, -0.8135,  0.2670,\n         -0.5531,  0.6016, -0.9271,  0.5655, -2.4451, -0.1605,  0.1804,  2.2347,\n         -0.6774,  0.8949,  0.9096,  0.4260,  1.2886, -0.1708, -0.8564, -0.6576,\n         -0.2041,  0.1203, -0.6191, -0.6317, -0.5774,  0.5874,  0.1230,  0.0885],\n        [-0.8708,  1.3073, -0.4785,  0.1740, -0.2219, -0.4277,  1.0395, -1.5168,\n         -0.2913,  0.7265,  1.3873, -0.6213,  1.0785, -0.1966,  1.1847,  0.8043,\n         -0.3349, -0.0659, -0.1244, -0.8531,  1.2268, -2.0151,  0.1955, -1.5921,\n         -0.5662,  0.4007, -0.7016,  0.1341,  1.9434,  1.0825, -1.5422,  0.6945],\n        [ 0.2914, -0.9938,  1.1093, -0.1230, -0.6921,  1.2534, -0.3842, -0.8658,\n         -1.1796, -1.0491, -1.0066, -0.4865,  0.1088, -1.0973,  1.9052,  0.3173,\n         -0.9864,  0.9211, -0.2568, -0.3576, -2.0254,  1.9583, -1.5720, -1.4571,\n         -1.0678,  1.4775, -0.1616,  1.0891, -0.6579,  1.5878, -0.7027,  0.7744],\n        [ 1.1941, -0.4634,  1.1772,  1.4375, -1.0653, -1.7664,  0.0840, -0.7976,\n          0.8627,  0.2296, -0.9099, -0.3386,  1.4792, -1.0326,  1.1311,  0.3852,\n          0.7320,  0.9011,  0.1835, -1.0502, -1.3660, -1.1291,  0.5201,  0.0946,\n         -0.0270, -0.0567,  0.0474,  0.7714, -0.9974, -0.7894,  0.4203, -1.6114],\n        [ 1.4981, -0.5602, -0.2473, -0.3447,  0.5629,  0.2425,  0.5914,  0.5201,\n         -0.3393, -1.2386,  1.3431, -1.8655, -0.6598,  0.7605,  0.5166,  2.7288,\n         -0.6033, -0.9709, -0.2074,  0.0469, -2.2953,  0.7799,  0.3482,  0.2761,\n          0.6437, -0.1594, -0.2394, -0.6779,  0.8675,  0.9428, -1.0349,  0.6668],\n        [ 0.3702, -0.3342,  0.6486, -1.7184,  1.3529,  0.0583, -0.9163,  0.4493,\n         -1.0142, -0.5802, -0.6917,  0.0961, -0.9206, -0.9769,  0.5708,  0.5485,\n          1.2039,  0.1723,  0.1098, -1.1271, -2.9914,  0.5820, -0.8222,  1.7128,\n          0.4903,  1.6712,  1.3292,  0.7209, -0.2522, -0.4198, -1.0689,  1.5453],\n        [-0.3562, -0.8442, -0.6643, -0.4708, -1.8949,  0.8131, -0.5936, -1.0812,\n         -2.3260, -1.1522,  0.0103,  1.7073,  0.1603, -0.9406, -1.8644,  1.4140,\n          0.1910,  1.0793,  3.3837,  0.7619,  1.1029,  0.6848, -0.8358,  0.4098,\n          0.7990,  0.6075, -0.0925, -0.7187,  0.1725,  0.4101, -1.4646, -1.3368],\n        [-1.1426,  0.3899,  0.9297,  1.2614,  1.0698,  1.0736,  0.6925, -0.3333,\n          1.2808,  0.7737,  1.2118, -0.2475, -0.4481,  0.5252,  1.9697, -0.8069,\n         -0.1349,  1.0063,  1.1844,  1.2995, -1.2506, -0.7795, -0.2368,  0.1901,\n          1.5115,  1.3860, -1.2020, -1.2845, -0.3620, -1.0303, -1.1296, -0.3098]])"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T22:53:19.145530300Z",
     "start_time": "2023-06-22T22:53:19.109276500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-9.0121e-01,  5.6559e-01, -4.8823e-01,  7.5070e-01,  5.8925e-01,\n         -4.5520e-01, -8.1355e-01,  2.6704e-01, -5.5314e-01,  6.0157e-01,\n         -9.2708e-01,  5.6554e-01, -2.4451e+00, -1.6050e-01,  1.8039e-01,\n          2.2347e+00, -6.7740e-01,  8.9492e-01,  9.0957e-01,  4.2604e-01,\n          1.2886e+00, -1.7080e-01, -8.5644e-01, -6.5758e-01, -2.0407e-01,\n          1.2033e-01, -6.1915e-01, -6.3168e-01, -5.7739e-01,  5.8742e-01,\n          1.2304e-01,  8.8526e-02],\n        [-8.8602e-01,  9.3642e-01, -4.8335e-01,  4.6237e-01,  1.8368e-01,\n         -4.4146e-01,  1.1298e-01, -6.2487e-01, -4.2224e-01,  6.6403e-01,\n          2.3012e-01, -2.7862e-02, -6.8331e-01, -1.7857e-01,  6.8256e-01,\n          1.5195e+00, -5.0616e-01,  4.1450e-01,  3.9257e-01, -2.1355e-01,\n          1.2577e+00, -1.0929e+00, -3.3046e-01, -1.1249e+00, -3.8512e-01,\n          2.6050e-01, -6.6037e-01, -2.4880e-01,  6.8301e-01,  8.3497e-01,\n         -7.0958e-01,  3.9150e-01],\n        [-4.9354e-01,  2.9302e-01,  4.7539e-02,  2.6725e-01, -1.0824e-01,\n          1.2348e-01, -5.2761e-02, -7.0518e-01, -6.7470e-01,  9.2982e-02,\n         -1.8213e-01, -1.8073e-01, -4.1929e-01, -4.8483e-01,  1.0901e+00,\n          1.1188e+00, -6.6625e-01,  5.8336e-01,  1.7613e-01, -2.6156e-01,\n          1.6335e-01, -7.5851e-02, -7.4431e-01, -1.2356e+00, -6.1268e-01,\n          6.6617e-01, -4.9410e-01,  1.9716e-01,  2.3604e-01,  1.0859e+00,\n         -7.0727e-01,  5.1915e-01],\n        [-7.1636e-02,  1.0390e-01,  3.2996e-01,  5.5982e-01, -3.4752e-01,\n         -3.4898e-01, -1.8576e-02, -7.2829e-01, -2.9034e-01,  1.2714e-01,\n         -3.6406e-01, -2.2020e-01,  5.5346e-02, -6.2176e-01,  1.1003e+00,\n          9.3537e-01, -3.1669e-01,  6.6279e-01,  1.7798e-01, -4.5871e-01,\n         -2.1899e-01, -3.3916e-01, -4.2822e-01, -9.0307e-01, -4.6627e-01,\n          4.8545e-01, -3.5871e-01,  3.4071e-01, -7.2323e-02,  6.1708e-01,\n         -4.2538e-01, -1.3485e-02],\n        [ 2.4230e-01, -2.8921e-02,  2.1452e-01,  3.7890e-01, -1.6543e-01,\n         -2.3068e-01,  1.0342e-01, -4.7861e-01, -3.0013e-01, -1.4600e-01,\n         -2.2618e-02, -5.4926e-01, -8.7689e-02, -3.4531e-01,  9.8359e-01,\n          1.2940e+00, -3.7400e-01,  3.3605e-01,  1.0089e-01, -3.5759e-01,\n         -6.3424e-01, -1.1535e-01, -2.7293e-01, -6.6723e-01, -2.4427e-01,\n          3.5648e-01, -3.3486e-01,  1.3700e-01,  1.1564e-01,  6.8223e-01,\n         -5.4729e-01,  1.2258e-01],\n        [ 2.6362e-01, -7.9804e-02,  2.8686e-01,  2.9357e-02,  8.7620e-02,\n         -1.8251e-01, -6.6531e-02, -3.2395e-01, -4.1914e-01, -2.1837e-01,\n         -1.3414e-01, -4.4170e-01, -2.2651e-01, -4.5057e-01,  9.1479e-01,\n          1.1698e+00, -1.1102e-01,  3.0876e-01,  1.0237e-01, -4.8585e-01,\n         -1.0271e+00,  8.6749e-04, -3.6448e-01, -2.7055e-01, -1.2184e-01,\n          5.7561e-01, -5.7507e-02,  2.3431e-01,  5.4328e-02,  4.9856e-01,\n         -6.3423e-01,  3.5971e-01],\n        [ 1.7507e-01, -1.8900e-01,  1.5097e-01, -4.2095e-02, -1.9560e-01,\n         -4.0277e-02, -1.4183e-01, -4.3212e-01, -6.9154e-01, -3.5178e-01,\n         -1.1351e-01, -1.3470e-01, -1.7125e-01, -5.2057e-01,  5.1777e-01,\n          1.2047e+00, -6.7879e-02,  4.1884e-01,  5.7113e-01, -3.0759e-01,\n         -7.2282e-01,  9.8577e-02, -4.3181e-01, -1.7336e-01,  9.7031e-03,\n          5.8016e-01, -6.2505e-02,  9.8165e-02,  7.1206e-02,  4.8593e-01,\n         -7.5285e-01,  1.1735e-01],\n        [ 1.0357e-02, -1.1663e-01,  2.4831e-01,  1.2085e-01, -3.7422e-02,\n          9.8961e-02, -3.7537e-02, -4.1977e-01, -4.4500e-01, -2.1110e-01,\n          5.2150e-02, -1.4880e-01, -2.0585e-01, -3.8985e-01,  6.9926e-01,\n          9.5323e-01, -7.6261e-02,  4.9228e-01,  6.4779e-01, -1.0670e-01,\n         -7.8880e-01, -1.1186e-02, -4.0744e-01, -1.2792e-01,  1.9743e-01,\n          6.8090e-01, -2.0494e-01, -7.4669e-02,  1.7061e-02,  2.9640e-01,\n         -7.9994e-01,  6.3955e-02]])"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T22:53:20.004788300Z",
     "start_time": "2023-06-22T22:53:19.953192600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "b=\n",
      "tensor([[1., 6.],\n",
      "        [6., 7.],\n",
      "        [0., 2.]])\n",
      "c=\n",
      "tensor([[1.0000, 6.0000],\n",
      "        [3.5000, 6.5000],\n",
      "        [2.3333, 5.0000]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(23)\n",
    "a = torch.tril(torch.ones(3,3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('b=')\n",
    "print(b)\n",
    "print('c=')\n",
    "print(c)\n",
    "#by taking advantage of matrix multiplication, we can create a tensor c where each entry is the average of the rows and columns of the previous entries of b"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T22:53:20.648631800Z",
     "start_time": "2023-06-22T22:53:20.603420700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now let's implement this approach into our vocabulary information\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "print(wei)\n",
    "xbow2 = wei @ x #(B, T, T) @ (B, T, C) ---> (B, T, C)\n",
    "torch.allclose(xbow, xbow2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T22:53:21.334227900Z",
     "start_time": "2023-06-22T22:53:21.269024600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[-9.0121e-01,  5.6559e-01, -4.8823e-01,  7.5070e-01,  5.8925e-01,\n          -4.5520e-01, -8.1355e-01,  2.6704e-01, -5.5314e-01,  6.0157e-01,\n          -9.2708e-01,  5.6554e-01, -2.4451e+00, -1.6050e-01,  1.8039e-01,\n           2.2347e+00, -6.7740e-01,  8.9492e-01,  9.0957e-01,  4.2604e-01,\n           1.2886e+00, -1.7080e-01, -8.5644e-01, -6.5758e-01, -2.0407e-01,\n           1.2033e-01, -6.1915e-01, -6.3168e-01, -5.7739e-01,  5.8742e-01,\n           1.2304e-01,  8.8526e-02],\n         [-8.8602e-01,  9.3642e-01, -4.8335e-01,  4.6237e-01,  1.8368e-01,\n          -4.4146e-01,  1.1298e-01, -6.2487e-01, -4.2224e-01,  6.6403e-01,\n           2.3012e-01, -2.7862e-02, -6.8331e-01, -1.7857e-01,  6.8256e-01,\n           1.5195e+00, -5.0616e-01,  4.1450e-01,  3.9257e-01, -2.1355e-01,\n           1.2577e+00, -1.0929e+00, -3.3046e-01, -1.1249e+00, -3.8512e-01,\n           2.6050e-01, -6.6037e-01, -2.4880e-01,  6.8301e-01,  8.3497e-01,\n          -7.0958e-01,  3.9150e-01],\n         [-4.9354e-01,  2.9302e-01,  4.7539e-02,  2.6725e-01, -1.0824e-01,\n           1.2348e-01, -5.2761e-02, -7.0518e-01, -6.7470e-01,  9.2982e-02,\n          -1.8213e-01, -1.8073e-01, -4.1929e-01, -4.8483e-01,  1.0901e+00,\n           1.1188e+00, -6.6625e-01,  5.8336e-01,  1.7613e-01, -2.6156e-01,\n           1.6335e-01, -7.5851e-02, -7.4431e-01, -1.2356e+00, -6.1268e-01,\n           6.6617e-01, -4.9410e-01,  1.9716e-01,  2.3604e-01,  1.0859e+00,\n          -7.0727e-01,  5.1915e-01],\n         [-7.1636e-02,  1.0390e-01,  3.2996e-01,  5.5982e-01, -3.4752e-01,\n          -3.4898e-01, -1.8576e-02, -7.2829e-01, -2.9034e-01,  1.2714e-01,\n          -3.6406e-01, -2.2020e-01,  5.5346e-02, -6.2176e-01,  1.1003e+00,\n           9.3537e-01, -3.1669e-01,  6.6279e-01,  1.7798e-01, -4.5871e-01,\n          -2.1899e-01, -3.3916e-01, -4.2822e-01, -9.0307e-01, -4.6627e-01,\n           4.8545e-01, -3.5871e-01,  3.4071e-01, -7.2323e-02,  6.1708e-01,\n          -4.2538e-01, -1.3485e-02],\n         [ 2.4230e-01, -2.8921e-02,  2.1452e-01,  3.7890e-01, -1.6543e-01,\n          -2.3068e-01,  1.0342e-01, -4.7861e-01, -3.0013e-01, -1.4600e-01,\n          -2.2618e-02, -5.4926e-01, -8.7689e-02, -3.4531e-01,  9.8359e-01,\n           1.2940e+00, -3.7400e-01,  3.3605e-01,  1.0089e-01, -3.5759e-01,\n          -6.3424e-01, -1.1535e-01, -2.7293e-01, -6.6723e-01, -2.4427e-01,\n           3.5648e-01, -3.3486e-01,  1.3700e-01,  1.1564e-01,  6.8223e-01,\n          -5.4729e-01,  1.2258e-01],\n         [ 2.6362e-01, -7.9804e-02,  2.8686e-01,  2.9357e-02,  8.7620e-02,\n          -1.8251e-01, -6.6531e-02, -3.2395e-01, -4.1914e-01, -2.1837e-01,\n          -1.3414e-01, -4.4170e-01, -2.2651e-01, -4.5057e-01,  9.1479e-01,\n           1.1698e+00, -1.1102e-01,  3.0876e-01,  1.0237e-01, -4.8585e-01,\n          -1.0271e+00,  8.6749e-04, -3.6448e-01, -2.7055e-01, -1.2184e-01,\n           5.7561e-01, -5.7507e-02,  2.3431e-01,  5.4328e-02,  4.9856e-01,\n          -6.3423e-01,  3.5971e-01],\n         [ 1.7507e-01, -1.8900e-01,  1.5097e-01, -4.2095e-02, -1.9560e-01,\n          -4.0277e-02, -1.4183e-01, -4.3212e-01, -6.9154e-01, -3.5178e-01,\n          -1.1351e-01, -1.3470e-01, -1.7125e-01, -5.2057e-01,  5.1777e-01,\n           1.2047e+00, -6.7879e-02,  4.1884e-01,  5.7113e-01, -3.0759e-01,\n          -7.2282e-01,  9.8577e-02, -4.3181e-01, -1.7336e-01,  9.7031e-03,\n           5.8016e-01, -6.2505e-02,  9.8165e-02,  7.1206e-02,  4.8593e-01,\n          -7.5285e-01,  1.1735e-01],\n         [ 1.0357e-02, -1.1663e-01,  2.4831e-01,  1.2085e-01, -3.7422e-02,\n           9.8961e-02, -3.7537e-02, -4.1977e-01, -4.4500e-01, -2.1110e-01,\n           5.2150e-02, -1.4880e-01, -2.0585e-01, -3.8985e-01,  6.9926e-01,\n           9.5323e-01, -7.6261e-02,  4.9228e-01,  6.4779e-01, -1.0670e-01,\n          -7.8880e-01, -1.1186e-02, -4.0744e-01, -1.2792e-01,  1.9743e-01,\n           6.8090e-01, -2.0494e-01, -7.4669e-02,  1.7061e-02,  2.9640e-01,\n          -7.9994e-01,  6.3955e-02]]),\n tensor([[-9.0121e-01,  5.6559e-01, -4.8823e-01,  7.5070e-01,  5.8925e-01,\n          -4.5520e-01, -8.1355e-01,  2.6704e-01, -5.5314e-01,  6.0157e-01,\n          -9.2708e-01,  5.6554e-01, -2.4451e+00, -1.6050e-01,  1.8039e-01,\n           2.2347e+00, -6.7740e-01,  8.9492e-01,  9.0957e-01,  4.2604e-01,\n           1.2886e+00, -1.7080e-01, -8.5644e-01, -6.5758e-01, -2.0407e-01,\n           1.2033e-01, -6.1915e-01, -6.3168e-01, -5.7739e-01,  5.8742e-01,\n           1.2304e-01,  8.8526e-02],\n         [-8.8602e-01,  9.3642e-01, -4.8335e-01,  4.6237e-01,  1.8368e-01,\n          -4.4146e-01,  1.1298e-01, -6.2487e-01, -4.2224e-01,  6.6403e-01,\n           2.3012e-01, -2.7862e-02, -6.8331e-01, -1.7857e-01,  6.8256e-01,\n           1.5195e+00, -5.0616e-01,  4.1450e-01,  3.9257e-01, -2.1355e-01,\n           1.2577e+00, -1.0929e+00, -3.3046e-01, -1.1249e+00, -3.8512e-01,\n           2.6050e-01, -6.6037e-01, -2.4880e-01,  6.8301e-01,  8.3497e-01,\n          -7.0958e-01,  3.9150e-01],\n         [-4.9354e-01,  2.9302e-01,  4.7539e-02,  2.6725e-01, -1.0824e-01,\n           1.2348e-01, -5.2761e-02, -7.0518e-01, -6.7470e-01,  9.2982e-02,\n          -1.8213e-01, -1.8073e-01, -4.1929e-01, -4.8483e-01,  1.0901e+00,\n           1.1188e+00, -6.6625e-01,  5.8336e-01,  1.7613e-01, -2.6156e-01,\n           1.6335e-01, -7.5851e-02, -7.4431e-01, -1.2356e+00, -6.1268e-01,\n           6.6617e-01, -4.9410e-01,  1.9716e-01,  2.3604e-01,  1.0859e+00,\n          -7.0727e-01,  5.1915e-01],\n         [-7.1636e-02,  1.0390e-01,  3.2996e-01,  5.5982e-01, -3.4752e-01,\n          -3.4898e-01, -1.8576e-02, -7.2829e-01, -2.9034e-01,  1.2714e-01,\n          -3.6406e-01, -2.2020e-01,  5.5346e-02, -6.2176e-01,  1.1003e+00,\n           9.3537e-01, -3.1669e-01,  6.6279e-01,  1.7798e-01, -4.5871e-01,\n          -2.1899e-01, -3.3916e-01, -4.2822e-01, -9.0307e-01, -4.6627e-01,\n           4.8545e-01, -3.5871e-01,  3.4071e-01, -7.2323e-02,  6.1708e-01,\n          -4.2538e-01, -1.3485e-02],\n         [ 2.4230e-01, -2.8921e-02,  2.1452e-01,  3.7890e-01, -1.6543e-01,\n          -2.3068e-01,  1.0342e-01, -4.7861e-01, -3.0013e-01, -1.4600e-01,\n          -2.2618e-02, -5.4926e-01, -8.7689e-02, -3.4531e-01,  9.8359e-01,\n           1.2940e+00, -3.7400e-01,  3.3605e-01,  1.0089e-01, -3.5759e-01,\n          -6.3424e-01, -1.1535e-01, -2.7293e-01, -6.6723e-01, -2.4427e-01,\n           3.5648e-01, -3.3486e-01,  1.3700e-01,  1.1564e-01,  6.8223e-01,\n          -5.4729e-01,  1.2258e-01],\n         [ 2.6362e-01, -7.9804e-02,  2.8686e-01,  2.9357e-02,  8.7620e-02,\n          -1.8251e-01, -6.6531e-02, -3.2395e-01, -4.1914e-01, -2.1837e-01,\n          -1.3414e-01, -4.4170e-01, -2.2651e-01, -4.5057e-01,  9.1479e-01,\n           1.1698e+00, -1.1102e-01,  3.0876e-01,  1.0237e-01, -4.8585e-01,\n          -1.0271e+00,  8.6747e-04, -3.6448e-01, -2.7055e-01, -1.2184e-01,\n           5.7561e-01, -5.7507e-02,  2.3431e-01,  5.4328e-02,  4.9856e-01,\n          -6.3423e-01,  3.5971e-01],\n         [ 1.7507e-01, -1.8900e-01,  1.5097e-01, -4.2095e-02, -1.9560e-01,\n          -4.0277e-02, -1.4183e-01, -4.3212e-01, -6.9154e-01, -3.5178e-01,\n          -1.1351e-01, -1.3470e-01, -1.7125e-01, -5.2057e-01,  5.1777e-01,\n           1.2047e+00, -6.7879e-02,  4.1884e-01,  5.7113e-01, -3.0759e-01,\n          -7.2282e-01,  9.8576e-02, -4.3181e-01, -1.7336e-01,  9.7031e-03,\n           5.8016e-01, -6.2505e-02,  9.8165e-02,  7.1206e-02,  4.8593e-01,\n          -7.5285e-01,  1.1735e-01],\n         [ 1.0357e-02, -1.1663e-01,  2.4831e-01,  1.2085e-01, -3.7422e-02,\n           9.8961e-02, -3.7537e-02, -4.1977e-01, -4.4500e-01, -2.1110e-01,\n           5.2150e-02, -1.4880e-01, -2.0585e-01, -3.8985e-01,  6.9926e-01,\n           9.5323e-01, -7.6261e-02,  4.9228e-01,  6.4779e-01, -1.0670e-01,\n          -7.8880e-01, -1.1186e-02, -4.0744e-01, -1.2792e-01,  1.9743e-01,\n           6.8090e-01, -2.0494e-01, -7.4669e-02,  1.7061e-02,  2.9640e-01,\n          -7.9994e-01,  6.3955e-02]]))"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0], xbow2[0]\n",
    "#exactly the same"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T22:53:22.685610200Z",
     "start_time": "2023-06-22T22:53:22.646263800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 8, 32])"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#yet another way to do this aggregation is the following:\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)\n",
    "#weighted aggregations by softmaxing a lower triangular matrix\n",
    "xbow3.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T22:53:23.483683500Z",
     "start_time": "2023-06-22T22:53:23.452512300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#query = what am i looking for\n",
    "#key = what do i contain\n",
    "#SELF ATTENTION!!!\n",
    "torch.manual_seed(23)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
